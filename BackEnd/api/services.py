import asyncio
import base64
import logging
import os
import re
from io import BytesIO
from random import choice
from typing import Optional
from pydantic import BaseModel
import time

import fal_client
import openai
import requests
from dotenv import load_dotenv
from fastapi import APIRouter, Form, File, UploadFile
from fastapi.responses import JSONResponse, StreamingResponse


load_dotenv()


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    force=True
)


router = APIRouter()
BFL_API_KEY = os.getenv("BFL_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY
BFL_ENDPOINT = "fal-ai/flux-pro/kontext"
VIDEO_MODEL_NAME = "kling-video/v2.1/standard/image-to-video"

STYLE_PROMPT = {
    "realistic": "semi_realistic, hyper-detailed, sharp focus, DSLR photo, documentary style, 100mm lens, soft natural lighting, perfect skin, editorial photo, 4k, k-fasion, designer clothes, stylisth",
    "2d": "anime, flat design aesthetic, vibrant colors, expressive eyes, clean line art, cel shading,k-fasion",
    "3d": "pixar-like animation style, smooth surfaces, cinematic lighting, subsurface scattering, warm and inviting lighting, cute 3D character, dreamy, k-fasion, designer clothes, stylisth",
    "cyberpunk": "cyberpunk, neon-soaked cityscape, dramatic backlighting, holographic elements, reflective surfaces, futuristic sci-fi fantasy",
    "dot": "8-bit pixel art character, full body, standing, retro video game sprite, visible pixels, blocky edges, choppy lines, limited color palette, pixel grid, low resolution, pixel art background, game screenshot, k-fasion, designer clothes, stylisth"
}

GENDER_KO_TO_EN = {
    "male": "male",
    "female": "female",
    "other": "gender-neutral"
}

AGE_MAP = {
    "9": "5-year-old",
    "10": "15-year-old",
    "20": "25-year-old",
    "30": "35-year-old",
    "40": "45-year-old",
    "50": "55-year-old",
    "60": "75-year-old"
}


def contains_korean(text: str) -> bool:

    return bool(re.search("[ê°€-í£]", text))


async def get_translated_text(text: str) -> str:

    if not OPENAI_API_KEY or not contains_korean(text):
        return text

    messages = [
        {
            "role": "system",
            "content": (
                "You are an AI artist. Given the user's input, imagine the scene and translate it into a vivid "
                "English prompt. The prompt must always include, in detail, a specific camera angle and composition "
                "(e.g., low-angle, side view, from behind), the background, environment, what the person is doing, "
                "surrounding objects, the mood, and the time, based on the user's input. Never, under any circumstances, "
                "describe the person's face or physical appearance. Write as if you are describing what you saw firsthand, "
                "vividly, and strictly from a third-person point of view."
            ),
        },
        {"role": "user", "content": text},
    ]

    try:
        response = await asyncio.to_thread(
            openai.ChatCompletion.create,
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.5,
            max_tokens=100,
            request_timeout=15,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"âŒ ìƒí™© í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return text


@router.post("/generate/image")
async def generate_image(
    text: str = Form(...),
    style: str = Form(""),
    age: str = Form(""),
    gender: str = Form(""),
    image: Optional[UploadFile] = File(None),
) -> JSONResponse:

    if not BFL_API_KEY:
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": "API key missing."}
        )

    translated_prompt = await get_translated_text(text)
    style_prompt = STYLE_PROMPT.get(style, choice(list(STYLE_PROMPT.values())))
    gender_en = GENDER_KO_TO_EN.get(gender, choice(list(GENDER_KO_TO_EN.values())))
    final_age = AGE_MAP.get(age, choice(list(AGE_MAP.values())))
    ethnicity_keyword = "Korean" if contains_korean(text) else ""
    paparazzi_prompt = (
        "not looking at the camera, full-body shot, candid,"
        "like a paparazzi photo, natural moment"
    )

    # --- case 1: dot ìŠ¤íƒ€ì¼ + ì–¼êµ´ ì‚½ì… ì—†ìŒ
    if style == "dot" and not image:
        subject_prompt = f"A {final_age} {ethnicity_keyword} {gender_en}"
        final_prompt_parts = [translated_prompt, style_prompt, subject_prompt]
        composed_prompt = ". ".join(filter(None, final_prompt_parts))
        payload = {
            "prompt": composed_prompt,
            "guidance_scale": 8,
            "num_images": 1,
            "output_format": "png",
            "aspect_ratio": "3:4",
            "negative_prompt": (
                "distorted face, blurry, ugly, side view, back view, "
                "turned away, face covered, shadow on face"
            ),
        }
        try:
            logging.info("ğŸŸ¡ dot ìŠ¤íƒ€ì¼ - ëœë¤ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘")
            img_result = await asyncio.to_thread(
                fal_client.run,
                BFL_ENDPOINT,
                arguments=payload
            )
            final_image_url = img_result["images"][0]["url"]
            image_response = requests.get(final_image_url, timeout=15)
            image_response.raise_for_status()
            encoded_image = base64.b64encode(image_response.content).decode("utf-8")
            data_uri = f"data:image/png;base64,{encoded_image}"
            logging.info("âœ… dot ìŠ¤íƒ€ì¼ - ëœë¤ ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ")
            return JSONResponse(content={"success": True, "image": data_uri})
        except Exception as e:
            logging.exception("âŒ dot ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
            return JSONResponse(
                status_code=500,
                content={"success": False, "error": str(e)}
            )

    # --- case 2: ì–¼êµ´ ì‚½ì…í•œ ê²½ìš° (ì°¸ì¡° ì´ë¯¸ì§€ ì‚¬ìš©)
    elif image:
        subject_prompt = f"photo of a {final_age} {ethnicity_keyword} {gender_en}"
        face_guidance_prompt = (
            "The face in the generated image must be a very close and exact match to the reference photo."
        )
        final_prompt_parts = [
            face_guidance_prompt,
            translated_prompt,
            style_prompt,
            subject_prompt,
            paparazzi_prompt,
        ]
        composed_prompt = ". ".join(filter(None, final_prompt_parts))
        image_bytes = await image.read()
        encoded_image = base64.b64encode(image_bytes).decode("utf-8")
        payload = {
            "prompt": composed_prompt,
            "guidance_scale": 3,
            "image_guidance_scale": 0.1,
            "num_images": 1,
            "output_format": "png",
            "aspect_ratio": "3:4",
            "image_url": f"data:image/png;base64,{encoded_image}",
            "negative_prompt": (
                "random face, distorted face, blurry, ugly, side view, back view, "
                "turned away, face covered, shadow on face"
            ),
        }
        try:
            logging.info("ğŸŸ¢ ì–¼êµ´ ì‚½ì… - ì´ë¯¸ì§€ ìƒì„± ì‹œì‘")
            img_result = await asyncio.to_thread(
                fal_client.run,
                BFL_ENDPOINT,
                arguments=payload
            )
            final_image_url = img_result["images"][0]["url"]
            image_response = requests.get(final_image_url, timeout=15)
            image_response.raise_for_status()
            encoded_image = base64.b64encode(image_response.content).decode("utf-8")
            data_uri = f"data:image/png;base64,{encoded_image}"
            logging.info("âœ… ì–¼êµ´ ì‚½ì… - ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ")
            return JSONResponse(content={"success": True, "image": data_uri})
        except Exception as e:
            logging.exception("âŒ ì–¼êµ´ ì‚½ì… ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
            return JSONResponse(
                status_code=500,
                content={"success": False, "error": str(e)}
            )

    # --- case 3: ì–¼êµ´ ì‚½ì… ì—†ìŒ, dot ìŠ¤íƒ€ì¼ë„ ì•„ë‹˜ â†’ ëœë¤ realistic ìƒì„±
    else:
        subject_prompt = f"A {final_age} {ethnicity_keyword} {gender_en}"
        final_prompt_parts = [
            translated_prompt,
            style_prompt,
            subject_prompt,
            paparazzi_prompt,
        ]
        composed_prompt = ". ".join(filter(None, final_prompt_parts))
        payload = {
            "prompt": composed_prompt,
            "guidance_scale": 3,
            "num_images": 1,
            "output_format": "png",
            "aspect_ratio": "3:4",
            "negative_prompt": (
                "distorted face, blurry, ugly, side view, back view, "
                "turned away, face covered, shadow on face"
            ),
        }
        try:
            logging.info("ğŸŸ  ì¼ë°˜ ëœë¤ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘")
            img_result = await asyncio.to_thread(
                fal_client.run,
                BFL_ENDPOINT,
                arguments=payload
            )
            final_image_url = img_result["images"][0]["url"]
            image_response = requests.get(final_image_url, timeout=15)
            image_response.raise_for_status()
            encoded_image = base64.b64encode(image_response.content).decode("utf-8")
            data_uri = f"data:image/png;base64,{encoded_image}"
            logging.info("âœ… ì¼ë°˜ ëœë¤ ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ")
            return JSONResponse(content={"success": True, "image": data_uri})
        except Exception as e:
            logging.exception("âŒ ì¼ë°˜ ëœë¤ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
            return JSONResponse(
                status_code=500,
                content={"success": False, "error": str(e)}
            )



@router.get("/generated_image_proxy")
def proxy_image(url: str) -> StreamingResponse:

    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        return StreamingResponse(
            BytesIO(response.content),
            media_type=response.headers["Content-Type"],
        )
    except Exception as e:
        logging.error(f"âŒ í”„ë¡ì‹œ ì´ë¯¸ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=404,
            content={"success": False, "error": "Image not found."}
        )


class VideoRequest(BaseModel):
    image_url: str

@router.post("/generate/video")
async def generate_video_from_image(req: VideoRequest):
    FIXED_VIDEO_PROMPT = "A 5-second video with a slow camera pan around the subject, cinematic, smooth movement."
    TIMEOUT_SECONDS = 30
    POLL_INTERVAL = 2

    try:
        if not req.image_url.startswith("data:image"):
            raise ValueError("data:image í˜•ì‹ì˜ base64ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

        _, encoded = req.image_url.split(",", 1)
        logging.info("ğŸ base64 ì˜ìƒ ìƒì„± ìš”ì²­ ì‹œì‘")

        result = await asyncio.to_thread(
            fal_client.run,
            f"fal-ai/{VIDEO_MODEL_NAME}",
            arguments={
                "prompt": FIXED_VIDEO_PROMPT,
                "image_base64": encoded,
                "duration": 5
            }
        )

        request_id = result.get("request_id")
        if not request_id:
            logging.error(f"âŒ Fal ì‘ë‹µì— request_id ì—†ìŒ: {result}")
            return JSONResponse(
                status_code=500,
                content={"success": False, "error": "Fal ì‘ë‹µì— request_id ì—†ìŒ"}
            )

        attempt = 0
        start_time = time.monotonic()
        while time.monotonic() - start_time < TIMEOUT_SECONDS:
            attempt += 1
            status = await asyncio.to_thread(fal_client.get_request, request_id)

            # 1. APIê°€ ë¶ˆì•ˆì •í•˜ì—¬ Noneì„ ë°˜í™˜í•˜ëŠ” ê²½ìš°ë¥¼ ë°©ì–´
            if not status:
                logging.warning(f"âš ï¸ Fal ìƒíƒœ ì‘ë‹µì´ ë¹„ì–´ìˆìŒ (ì‹œë„: #{attempt})")
                await asyncio.sleep(POLL_INTERVAL)
                continue

            state = status.get("status")

            # 2. DEBUG ë ˆë²¨ë¡œ í˜„ì¬ ìƒíƒœë¥¼ ìƒì„¸íˆ ë¡œê¹…í•˜ì—¬ ì¶”ì  ìš©ì´ì„± í™•ë³´
            logging.debug(f"ğŸ” ì˜ìƒ ìƒíƒœ ì²´í¬ #{attempt}: {state}")

            if state == "succeeded":
                video_url = status.get("video", {}).get("url")
                if video_url:
                    logging.info(f"âœ… ì˜ìƒ ìƒì„± ì™„ë£Œ (url: {video_url})")
                    return JSONResponse(content={"success": True, "video_url": video_url})
                else:
                    logging.error(f"âŒ ì‘ë‹µì— video_url ì—†ìŒ: {status}")
                    return JSONResponse(
                        status_code=500,
                        content={"success": False, "error": "Video URL not found in response."}
                    )
            elif state == "failed":
                logging.error(f"âŒ Fal ì‘ë‹µ: ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {status}")
                return JSONResponse(
                    status_code=500,
                    content={"success": False, "error": "Video generation failed."}
                )

            await asyncio.sleep(POLL_INTERVAL)

        # while ë£¨í”„ê°€ ì •ìƒì ìœ¼ë¡œ ëë‚˜ë©´ íƒ€ì„ì•„ì›ƒ
        logging.error(f"â° ì˜ìƒ ìƒì„± ìš”ì²­ íƒ€ì„ì•„ì›ƒ (Request ID: {request_id})")
        return JSONResponse(
            status_code=504,
            content={"success": False, "error": "Video generation timed out."}
        )

    except Exception as e:
        # 3. ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì „ì²´ë¥¼ ê¸°ë¡í•˜ì—¬ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ì˜ ì›ì¸ ë¶„ì„ ìš©ì´
        logging.exception(f"âŒ ì˜ìƒ ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜ˆì™¸ ë°œìƒ: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": "An unexpected error occurred during video generation."}
        )